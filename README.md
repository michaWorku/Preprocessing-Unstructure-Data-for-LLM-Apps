# **Preprocessing Unstructured Data for LLM Applications**  

This repository contains course materials and code implementations for [**Preprocessing Unstructured Data for LLM Applications**](https://www.deeplearning.ai/short-courses/preprocessing-unstructured-data-for-llm-applications/). The course explores techniques for processing diverse document typesâ€”**PDFs, Word, PowerPoint, HTML, tables, and images**â€”to enhance the accuracy and relevance of **Retrieval-Augmented Generation (RAG)** applications.  


## **ğŸ“Œ Course Overview**  
To improve **RAG system performance**, it's essential to extract, normalize, and enrich unstructured data from various sources. This course covers:  

âœ… **Preprocessing Unstructured Data** â€“ Converting text, images, and tables into structured formats for LLMs.  
âœ… **Metadata Enrichment** â€“ Enhancing retrieval and search performance.  
âœ… **Document Image Analysis** â€“ Applying **layout detection, vision transformers, and table transformers** for better text and structure extraction.  
âœ… **Building a Multi-Source RAG Pipeline** â€“ Extending LLMs to process **Excel, Word, PowerPoint, PDFs, and EPUBs**.  

By the end of the course, you'll be able to **build a RAG-powered chatbot** capable of handling diverse document formats. ğŸš€  


## **ğŸ“‚ Course Contents**  

### **1ï¸âƒ£ Overview of LLM Data Preprocessing**  
- **Understanding RAG Systems** â€“ How LLMs use structured and unstructured data for enhanced responses.  
- **Document Content & Metadata** â€“ Extracting and organizing document elements (titles, text, lists, tables, images).  
- **Challenges in Preprocessing** â€“ Standardizing different document types, handling extraction variability, and leveraging metadata for search.  

### [**2ï¸âƒ£ Normalizing the Content**](https://github.com/michaWorku/Preprocessing-Unstructure-Data-for-LLM-Apps/tree/main/L2_Normalizing_the_content)  
- **Format Diversity & Common Format Standardization** â€“ Converting different documents into a structured JSON format.  
- **Benefits of Normalization** â€“ Filtering unwanted elements, chunking content, and reducing processing costs.  
- **Data Serialization** â€“ Using **JSON and JSONL** for structured storage and retrieval.  

### [**3ï¸âƒ£ Metadata Extraction & Chunking** ](https://github.com/michaWorku/Preprocessing-Unstructure-Data-for-LLM-Apps/tree/main/L3_Metadata_Extraction_Chunking) 
- **Metadata for Hybrid Search** â€“ Extracting document details (filename, filetype, sections) for better retrieval.  
- **Semantic Search with Vector Databases** â€“ Embedding documents for similarity-based search.  
- **Hybrid Search Strategies** â€“ Combining semantic search with filtering and keyword search.  
- **Chunking Techniques** â€“ Splitting documents into meaningful sections to improve retrieval and prompt generation.  

### [**4ï¸âƒ£ Preprocessing PDFs and Images**](https://github.com/michaWorku/Preprocessing-Unstructure-Data-for-LLM-Apps/tree/main/L4_Preprocessing_PDF_Images)  
- **Document Image Analysis (DIA)** â€“ Extracting structured data from scanned documents and PDFs.  
- **Document Layout Detection (DLD)** â€“ Using computer vision to detect elements in document images.  
- **Vision Transformers (ViTs)** â€“ Converting document images directly into structured JSON outputs.  
- **Comparison of Methods** â€“ Trade-offs between document layout models and vision transformers.  

### [**5ï¸âƒ£ Extracting Tables from Documents**](https://github.com/michaWorku/Preprocessing-Unstructure-Data-for-LLM-Apps/tree/main/L5_Extracting_Tables)  
- **Table Extraction Challenges** â€“ Handling structured data in unstructured documents.  
- **Table Transformers & OCR Postprocessing** â€“ Extracting tables using deep learning models.  
- **HTML Table Representation** â€“ Preserving table structures for better downstream processing.  

### [**6ï¸âƒ£ Building Your Own RAG Bot**](https://github.com/michaWorku/Preprocessing-Unstructure-Data-for-LLM-Apps/tree/main/L6_QA_RAG_Bot)  
- **Preprocessing PDFs, PowerPoint Slides, and ReadMe Files**  
- **Loading Documents into a Vector Database**  
- **Building a RAG Chatbot using LangChain**  


## **ğŸ›  Technologies & Tools Used**  
ğŸ”¹ **Python** â€“ For preprocessing and model implementation.  
ğŸ”¹ **LangChain** â€“ Building the RAG-powered chatbot.  
ğŸ”¹ **Vector Databases** â€“ Storing and retrieving embeddings.  
ğŸ”¹ **OCR & Transformers** â€“ Extracting text and structures from complex documents.  


## **ğŸš€ Getting Started**  

### **Installation**  
```bash
git clone https://github.com/michaWorku/Preprocessing-Unstructure-Data-for-LLM-Apps.git
cd preprocessing-llm-data
pip install -r requirements.txt
```

### **Running the Notebook**  
Run the Jupyter notebook to explore hands-on implementations:  
```bash
jupyter notebook
```

---

## **ğŸ“– Conclusion**  
By following this [course](https://www.deeplearning.ai/short-courses/preprocessing-unstructured-data-for-llm-applications/), you'll gain **practical skills** in **data preprocessing for LLMs**, enabling you to build **robust RAG applications** that process diverse document types efficiently. ğŸŒğŸ’¡  

Happy coding! ğŸš€
